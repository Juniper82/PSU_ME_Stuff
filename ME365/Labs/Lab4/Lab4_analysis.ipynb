{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import os\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets path for data files and reads them into a dictionary\n",
    "path = '~/GIT/PSU_ME_Stuff/ME365/Labs/Lab4/'\n",
    "files = ['Lab4_420G4.xlsx','Lab4_440AG4.xlsx','Lab4_Nimark_300G4.xlsx','Lab4_Custom_455G4.xlsx']\n",
    "dfKeys = ['dat420','dat440','dat455','dat300']\n",
    "\n",
    "dfs = {}\n",
    "for df,filename in zip(dfKeys,files):\n",
    "    dfs[df]=(pd.read_excel(path+filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dat420':    Sample  Thickness  %Reduction     1   2     3   4 scale\n",
       " 0       1      0.258         NaN  93.5  95  95.0  93     B\n",
       " 1       2      0.237    8.139535  93.5  99  98.5  99     B\n",
       " 2       3      0.213   17.441860  21.0  20  21.0  20     C\n",
       " 3       4      0.154   40.310078  26.0  26  26.0  26     C\n",
       " 4       5      0.106   58.914729  30.0  30  30.0  30     C,\n",
       " 'dat440':    Sample  Thickness  %Reduction   1   2   3   4 scale\n",
       " 0       5      0.084         NaN  96  97  97  97     B\n",
       " 1       4      0.077    8.333333  22  22  22  22     C\n",
       " 2       3      0.065   22.619048  26  27  25  25     C\n",
       " 3       2      0.052   38.095238  28  27  28  31     C\n",
       " 4       1      0.040   52.380952  29  29  30  29     C,\n",
       " 'dat455':    Sample  Thickness  %Reduction   1   2   3   4 scale\n",
       " 0       1      0.080         NaN  32  32  33  31     C\n",
       " 1       2      0.072       34.00  32  32  33  34     C\n",
       " 2       3      0.065       18.75  35  34  35  35     C\n",
       " 3       4      0.057       28.75  32  33  33  32     C\n",
       " 4       5      0.043       46.25  32  33  34  32     C,\n",
       " 'dat300':    Sample  Thickness  %Reduction   1   2   3     4 scale\n",
       " 0       1      0.091         NaN  30  30  30  30.0     C\n",
       " 1       2      0.080   12.087912  30  30  31  30.0     C\n",
       " 2       3      0.072   20.879121  30  29  30  31.0     C\n",
       " 3       4      0.053   41.758242  31  31  30  32.0     C\n",
       " 4       5      0.048   47.252747  34  33  34  35.5     C}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all Rockwell B to C for 440 data\n",
    "dfs['dat440'].iloc[0,3] = 18\n",
    "dfs['dat440'].iloc[0,4:7] = 20\n",
    "\n",
    "# Convert all Rockwell B to C for \n",
    "def interpolate(x1,x2,y1,y2,X):\n",
    "    \n",
    "    return y1 + (y1 - y2)*(X - x1)/(x1 - x2)\n",
    "\n",
    "x1 = 93\n",
    "x2 = 94\n",
    "X = 93.5\n",
    "y1 = 13\n",
    "y2 = 15\n",
    "dfs['dat420'].iloc[0:2,3] = interpolate(x1,x2,y1,y2,X)\n",
    "x1 = 98\n",
    "x2 = 99\n",
    "X = 98.5\n",
    "y1 = 21\n",
    "y2 = 22\n",
    "dfs['dat420'].iloc[1,5] = interpolate(x1,x2,y1,y2,X)\n",
    "dfs['dat420'].iloc[0,4:6] = 16.\n",
    "dfs['dat420'].iloc[0,6] = 13.\n",
    "dfs['dat420'].iloc[1,4] = 22.\n",
    "dfs['dat420'].iloc[1,6] = 22.\n",
    "dfs['dat420'].iloc[0:2,7] = 'C'\n",
    "dfs['dat440'].iloc[0,7] = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4469118487916806\n"
     ]
    }
   ],
   "source": [
    "# Retrieve t-stat value from the \"chart\" TINV(a,v) 95% confidence interval\n",
    "alpha = .05\n",
    "t = stats.t.ppf(1-alpha/2,df=6)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dat420 \n",
      "    Sample  Thickness  %Reduction     1     2     3     4 scale\n",
      "0       1      0.258         NaN  14.0  16.0  16.0  13.0     C\n",
      "1       2      0.237    8.139535  14.0  22.0  21.5  22.0     C\n",
      "2       3      0.213   17.441860  21.0  20.0  21.0  20.0     C\n",
      "3       4      0.154   40.310078  26.0  26.0  26.0  26.0     C\n",
      "4       5      0.106   58.914729  30.0  30.0  30.0  30.0     C \n",
      "\n",
      "dat440 \n",
      "    Sample  Thickness  %Reduction   1   2   3   4 scale\n",
      "0       5      0.084         NaN  18  20  20  20     C\n",
      "1       4      0.077    8.333333  22  22  22  22     C\n",
      "2       3      0.065   22.619048  26  27  25  25     C\n",
      "3       2      0.052   38.095238  28  27  28  31     C\n",
      "4       1      0.040   52.380952  29  29  30  29     C \n",
      "\n",
      "dat455 \n",
      "    Sample  Thickness  %Reduction   1   2   3   4 scale\n",
      "0       1      0.080         NaN  32  32  33  31     C\n",
      "1       2      0.072       34.00  32  32  33  34     C\n",
      "2       3      0.065       18.75  35  34  35  35     C\n",
      "3       4      0.057       28.75  32  33  33  32     C\n",
      "4       5      0.043       46.25  32  33  34  32     C \n",
      "\n",
      "dat300 \n",
      "    Sample  Thickness  %Reduction   1   2   3     4 scale\n",
      "0       1      0.091         NaN  30  30  30  30.0     C\n",
      "1       2      0.080   12.087912  30  30  31  30.0     C\n",
      "2       3      0.072   20.879121  30  29  30  31.0     C\n",
      "3       4      0.053   41.758242  31  31  30  32.0     C\n",
      "4       5      0.048   47.252747  34  33  34  35.5     C \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfKeys:\n",
    " \n",
    "    print(df,'\\n',dfs[df],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This mess creates a function that does the rest of the statistcal calculations and writes it to DataFrames\n",
    "def trueMean(dfs,n1,n2):\n",
    "    alpha = .05\n",
    "    t = stats.t.ppf(1.-alpha/2.,df=6)\n",
    "    #print t\n",
    "    v1 = n1-1\n",
    "    v2 = n2-1\n",
    "    df = n1+n2-2\n",
    "    v = v1+v2\n",
    "    for df in dfs.keys():\n",
    "        df = dfs[df]\n",
    "        df['mean_hardness'] = 0.\n",
    "        df['std'] = 0.\n",
    "        \n",
    "        #df['true_mean+'] = 0.\n",
    "        #df['true_mean-'] = 0.\n",
    "        #df['meanDiff'] =''\n",
    "       \n",
    "        for i in range(5):\n",
    "            df.loc[i,'mean_hardness'] = sum(df.iloc[i,3:7])/4.   \n",
    "            df.loc[i,'std'] = df.iloc[i,3:7].std()\n",
    "            if i >=1:\n",
    "                \n",
    "                df.loc[i,'Sx'] = np.sqrt((v1*(df.loc[0,'std'])**2+v2*(df.loc[i,'std'])**2)/(v))\n",
    "            else:\n",
    "                #print(df)\n",
    "                df.loc[i,'Sx'] = 'NaN'\n",
    "        for i in range(5):\n",
    "            \n",
    "            if i >= 1:\n",
    "                df.loc[i,'true_mean+'] = df.loc[0,'mean_hardness']-df.loc[i,'mean_hardness'] + t*df.loc[i,'Sx']*np.sqrt(1/n1+1/n2)\n",
    "                df.loc[i,'true_mean-'] = df.loc[0,'mean_hardness']-df.loc[i,'mean_hardness'] - t*df.loc[i,'Sx']*np.sqrt(1/n1+1/n2)\n",
    "                #print(df.loc[0,'mean_hardness'],df.loc[i,'mean_hardness'])\n",
    "            else:\n",
    "                df.loc[i,'true_mean+'] = 'NaN'\n",
    "                df.loc[i,'true_mean-'] = 'NaN'\n",
    "                df.loc[i,'meanDiff'] ='NaN'\n",
    "            if df.loc[i,'true_mean+'] != 'NaN' and df.loc[i,'true_mean-'] != 'NaN':\n",
    "                if df.loc[i,'true_mean+'] < 0 and df.loc[i,'true_mean-'] < 0 or df.loc[i,'true_mean+'] > 0 and df.loc[i,'true_mean-'] > 0:\n",
    "                    df.loc[i,'meanDiff'] = 'Yes'\n",
    "                \n",
    "                else:\n",
    "                    df.loc[i,'meanDiff'] = 'No'\n",
    "    return('Statiscal Analysis Successful\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statiscal Analysis Successful\n",
      "\n",
      "\n",
      "Type 420 G4\n",
      "\n",
      "    Sample  Thickness  %Reduction     1     2     3     4 scale  mean_hardness  \\\n",
      "0       1      0.258         NaN  14.0  16.0  16.0  13.0     C         14.750   \n",
      "1       2      0.237    8.139535  14.0  22.0  21.5  22.0     C         19.875   \n",
      "2       3      0.213   17.441860  21.0  20.0  21.0  20.0     C         20.500   \n",
      "3       4      0.154   40.310078  26.0  26.0  26.0  26.0     C         26.000   \n",
      "4       5      0.106   58.914729  30.0  30.0  30.0  30.0     C         30.000   \n",
      "\n",
      "        std       Sx true_mean+ true_mean- meanDiff  \n",
      "0  1.500000      NaN        NaN        NaN      NaN  \n",
      "1  3.923752  2.97034  0.0143644   -10.2644       No  \n",
      "2  0.577350  1.13652   -3.78357   -7.71643      Yes  \n",
      "3  0.000000  1.06066   -9.41482   -13.0852      Yes  \n",
      "4  0.000000  1.06066   -13.4148   -17.0852      Yes  \n",
      "\n",
      "Type 440 G4\n",
      "\n",
      "    Sample  Thickness  %Reduction   1   2   3   4 scale  mean_hardness  \\\n",
      "0       5      0.084         NaN  18  20  20  20     C          19.50   \n",
      "1       4      0.077    8.333333  22  22  22  22     C          22.00   \n",
      "2       3      0.065   22.619048  26  27  25  25     C          25.75   \n",
      "3       2      0.052   38.095238  28  27  28  31     C          28.50   \n",
      "4       1      0.040   52.380952  29  29  30  29     C          29.25   \n",
      "\n",
      "        std        Sx true_mean+ true_mean- meanDiff  \n",
      "0  1.000000       NaN        NaN        NaN      NaN  \n",
      "1  0.000000  0.707107   -1.27654   -3.72346      Yes  \n",
      "2  0.957427  0.978945    -4.5562    -7.9438      Yes  \n",
      "3  1.732051   1.41421   -6.55309   -11.4469      Yes  \n",
      "4  0.500000  0.790569   -8.38213   -11.1179      Yes  \n",
      "\n",
      "Type 455 G4\n",
      "\n",
      "    Sample  Thickness  %Reduction   1   2   3   4 scale  mean_hardness  \\\n",
      "0       1      0.080         NaN  32  32  33  31     C          32.00   \n",
      "1       2      0.072       34.00  32  32  33  34     C          32.75   \n",
      "2       3      0.065       18.75  35  34  35  35     C          34.75   \n",
      "3       4      0.057       28.75  32  33  33  32     C          32.50   \n",
      "4       5      0.043       46.25  32  33  34  32     C          32.75   \n",
      "\n",
      "        std        Sx true_mean+ true_mean- meanDiff  \n",
      "0  0.816497       NaN        NaN        NaN      NaN  \n",
      "1  0.957427  0.889757   0.789482   -2.28948       No  \n",
      "2  0.500000  0.677003   -1.57863   -3.92137      Yes  \n",
      "3  0.577350  0.707107   0.723456   -1.72346       No  \n",
      "4  0.957427  0.889757   0.789482   -2.28948       No  \n",
      "\n",
      "Type300 G4\n",
      "\n",
      "    Sample  Thickness  %Reduction   1   2   3     4 scale  mean_hardness  \\\n",
      "0       1      0.091         NaN  30  30  30  30.0     C         30.000   \n",
      "1       2      0.080   12.087912  30  30  31  30.0     C         30.250   \n",
      "2       3      0.072   20.879121  30  29  30  31.0     C         30.000   \n",
      "3       4      0.053   41.758242  31  31  30  32.0     C         31.000   \n",
      "4       5      0.048   47.252747  34  33  34  35.5     C         34.125   \n",
      "\n",
      "        std        Sx  true_mean+ true_mean- meanDiff  \n",
      "0  0.000000       NaN         NaN        NaN      NaN  \n",
      "1  0.500000  0.353553    0.361728  -0.861728       No  \n",
      "2  0.816497   0.57735    0.998948  -0.998948       No  \n",
      "3  0.816497   0.57735 -0.00105242   -1.99895      Yes  \n",
      "4  1.030776  0.728869    -2.86389   -5.38611      Yes  \n"
     ]
    }
   ],
   "source": [
    "# This \n",
    "#dfs = [dat420,dat440,dat455,dat300]\n",
    "print(trueMean(dfs,4,4))\n",
    "#print trueMean(dfs,5.,5.)\n",
    "print('Type 420 G4\\n\\n',dfs['dat420'])\n",
    "print('\\nType 440 G4\\n\\n',dfs['dat440'])\n",
    "print('\\nType 455 G4\\n\\n',dfs['dat455'])\n",
    "print('\\nType300 G4\\n\\n',dfs['dat300'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = '~/GIT/PSU_ME_Stuff/ME365/Labs/Lab4/'\n",
    "#files = ['Lab4_420G4_stat.xlsx','Lab4_440AG4_stat.xlsx','Lab4_Custom_455G4_stat.xlsx','Lab4_Nimark_300G4_stat.xlsx']\n",
    "#for df,fileName in zip(dfs.keys(),files):\n",
    "#    dfs[df].to_excel(path + fileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
