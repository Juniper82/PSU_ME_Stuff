{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import os\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets path for data files and reads them into a dictionary\n",
    "path = '~/Documents/ME365/Lab4/'\n",
    "files = ['Lab4_420G4.xlsx','Lab4_440AG4.xlsx','Lab4_Nimark_300G4.xlsx','Lab4_Custom_455G4.xlsx']\n",
    "dfKeys = ['dat420','dat440','dat455','dat300']\n",
    "\n",
    "dfs = {}\n",
    "for df,filename in zip(dfKeys,files):\n",
    "    dfs[df]=(pd.read_excel(path+filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dat300':    Sample  Thickness  %Reduction   1   2   3     4 scale\n",
       " 0       1      0.091         NaN  30  30  30  30.0     C\n",
       " 1       2      0.080   12.087912  30  30  31  30.0     C\n",
       " 2       3      0.072   20.879121  30  29  30  31.0     C\n",
       " 3       4      0.053   41.758242  31  31  30  32.0     C\n",
       " 4       5      0.048   47.252747  34  33  34  35.5     C,\n",
       " 'dat420':    Sample  Thickness  %Reduction     1   2     3   4 scale\n",
       " 0       1      0.258         NaN  93.5  95  95.0  93     B\n",
       " 1       2      0.237    8.139535  93.5  99  98.5  99     B\n",
       " 2       3      0.213   17.441860  21.0  20  21.0  20     C\n",
       " 3       4      0.154   40.310078  26.0  26  26.0  26     C\n",
       " 4       5      0.106   58.914729  30.0  30  30.0  30     C,\n",
       " 'dat440':    Sample  Thickness  %Reduction   1   2   3   4 scale\n",
       " 0       5      0.084         NaN  96  97  97  97     B\n",
       " 1       4      0.077    8.333333  22  22  22  22     C\n",
       " 2       3      0.065   22.619048  26  27  25  25     C\n",
       " 3       2      0.052   38.095238  28  27  28  31     C\n",
       " 4       1      0.040   52.380952  29  29  30  29     C,\n",
       " 'dat455':    Sample  Thickness  %Reduction   1   2   3   4 scale\n",
       " 0       1      0.080         NaN  32  32  33  31     C\n",
       " 1       2      0.072       34.00  32  32  33  34     C\n",
       " 2       3      0.065       18.75  35  34  35  35     C\n",
       " 3       4      0.057       28.75  32  33  33  32     C\n",
       " 4       5      0.043       46.25  32  33  34  32     C}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all Rockwell B to C for 440 data\n",
    "dfs['dat440'].iloc[0,3] = 18\n",
    "dfs['dat440'].iloc[0,4:7] = 20\n",
    "\n",
    "# Convert all Rockwell B to C for \n",
    "def interpolate(x1,x2,y1,y2,X):\n",
    "    \n",
    "    return y1 + (y1 - y2)*(X - x1)/(x1 - x2)\n",
    "\n",
    "x1 = 93\n",
    "x2 = 94\n",
    "X = 93.5\n",
    "y1 = 13\n",
    "y2 = 15\n",
    "dfs['dat420'].iloc[0:2,3] = interpolate(x1,x2,y1,y2,X)\n",
    "x1 = 98\n",
    "x2 = 99\n",
    "X = 98.5\n",
    "y1 = 21\n",
    "y2 = 22\n",
    "dfs['dat420'].iloc[1,5] = interpolate(x1,x2,y1,y2,X)\n",
    "dfs['dat420'].iloc[0,4:6] = 16.\n",
    "dfs['dat420'].iloc[0,6] = 13.\n",
    "dfs['dat420'].iloc[1,4] = 22.\n",
    "dfs['dat420'].iloc[1,6] = 22.\n",
    "dfs['dat420'].iloc[0:2,7] = 'C'\n",
    "dfs['dat440'].iloc[0,7] = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4469118487916806\n"
     ]
    }
   ],
   "source": [
    "# Retrieve t-stat value from the \"chart\" TINV(a,v) 95% confidence interval\n",
    "alpha = .05\n",
    "t = stats.t.ppf(1-alpha/2,df=6)\n",
    "print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dat420 \n",
      "   Sample  Thickness  %Reduction     1     2     3     4 scale\n",
      "0       1      0.258         NaN  14.0  16.0  16.0  13.0     C\n",
      "1       2      0.237    8.139535  14.0  22.0  21.5  22.0     C\n",
      "2       3      0.213   17.441860  21.0  20.0  21.0  20.0     C\n",
      "3       4      0.154   40.310078  26.0  26.0  26.0  26.0     C\n",
      "4       5      0.106   58.914729  30.0  30.0  30.0  30.0     C \n",
      "\n",
      "dat440 \n",
      "   Sample  Thickness  %Reduction   1   2   3   4 scale\n",
      "0       5      0.084         NaN  18  20  20  20     C\n",
      "1       4      0.077    8.333333  22  22  22  22     C\n",
      "2       3      0.065   22.619048  26  27  25  25     C\n",
      "3       2      0.052   38.095238  28  27  28  31     C\n",
      "4       1      0.040   52.380952  29  29  30  29     C \n",
      "\n",
      "dat455 \n",
      "   Sample  Thickness  %Reduction   1   2   3   4 scale\n",
      "0       1      0.080         NaN  32  32  33  31     C\n",
      "1       2      0.072       34.00  32  32  33  34     C\n",
      "2       3      0.065       18.75  35  34  35  35     C\n",
      "3       4      0.057       28.75  32  33  33  32     C\n",
      "4       5      0.043       46.25  32  33  34  32     C \n",
      "\n",
      "dat300 \n",
      "   Sample  Thickness  %Reduction   1   2   3     4 scale\n",
      "0       1      0.091         NaN  30  30  30  30.0     C\n",
      "1       2      0.080   12.087912  30  30  31  30.0     C\n",
      "2       3      0.072   20.879121  30  29  30  31.0     C\n",
      "3       4      0.053   41.758242  31  31  30  32.0     C\n",
      "4       5      0.048   47.252747  34  33  34  35.5     C \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfKeys:\n",
    " \n",
    "    print df,'\\n',dfs[df],'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This mess creates a function that does the rest of the statistcal calculations and writes it to DataFrames\n",
    "def trueMean(dfs,n1,n2):\n",
    "    alpha = .05\n",
    "    t = stats.t.ppf(1.-alpha/2.,df=6)\n",
    "    #print t\n",
    "    v1 = n1-1\n",
    "    v2 = n2-1\n",
    "    df = n1+n2-2\n",
    "    v = v1+v2\n",
    "    for df in dfs.keys():\n",
    "        df = dfs[df]\n",
    "        df['mean_hardness'] = 0.\n",
    "        df['std'] = 0.\n",
    "        df['Sx'] = 0.\n",
    "        df['true_mean+'] = 0.\n",
    "        df['true_mean-'] = 0.\n",
    "       \n",
    "        for i in range(5):\n",
    "            df['mean_hardness'].loc[i] = sum(df.iloc[i,3:7])/4.   \n",
    "            df['std'].iloc[i] = df.iloc[i,3:7].std()\n",
    "            df.Sx.iloc[i] = (v1*df['std'].iloc[0]+v2*df['std'].iloc[i])/(v)\n",
    "    for df in dfs.keys():\n",
    "        df = dfs[df]\n",
    "        \n",
    "        for i in range(5):\n",
    "            \n",
    "            if i >= 1:\n",
    "                df['true_mean+'].iloc[i] = df['mean_hardness'].iloc[0]-df['mean_hardness'].iloc[i] + t*df.Sx[i]*np.sqrt(1/n1+1/n2)\n",
    "                df['true_mean-'].iloc[i] = df['mean_hardness'].iloc[0]-df['mean_hardness'].iloc[i] - t*df.Sx[i]*np.sqrt(1/n1+1/n2)\n",
    "           \n",
    "            else:\n",
    "                df['true_mean+'].iloc[i] = 'NaN'\n",
    "                df['true_mean-'].iloc[i] = 'NaN'\n",
    "            \n",
    "    return('Statiscal Analysis Successful\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/.local/lib/python2.7/site-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statiscal Analysis Successful\n",
      "\n",
      "\n",
      "dat420\n",
      "\n",
      "   Sample  Thickness  %Reduction     1     2     3     4 scale  mean_hardness  \\\n",
      "0       1      0.258         NaN  14.0  16.0  16.0  13.0     C         14.750   \n",
      "1       2      0.237    8.139535  14.0  22.0  21.5  22.0     C         19.875   \n",
      "2       3      0.213   17.441860  21.0  20.0  21.0  20.0     C         20.500   \n",
      "3       4      0.154   40.310078  26.0  26.0  26.0  26.0     C         26.000   \n",
      "4       5      0.106   58.914729  30.0  30.0  30.0  30.0     C         30.000   \n",
      "\n",
      "        std        Sx true_mean+ true_mean-  \n",
      "0  1.500000  1.500000        NaN        NaN  \n",
      "1  3.923752  2.711876  -0.928201    -9.3218  \n",
      "2  0.577350  1.038675   -4.14258   -7.35742  \n",
      "3  0.000000  0.750000   -10.0893   -12.4107  \n",
      "4  0.000000  0.750000   -14.0893   -16.4107  \n",
      "\n",
      "dat440\n",
      "\n",
      "   Sample  Thickness  %Reduction   1   2   3   4 scale  mean_hardness  \\\n",
      "0       5      0.084         NaN  18  20  20  20     C          19.50   \n",
      "1       4      0.077    8.333333  22  22  22  22     C          22.00   \n",
      "2       3      0.065   22.619048  26  27  25  25     C          25.75   \n",
      "3       2      0.052   38.095238  28  27  28  31     C          28.50   \n",
      "4       1      0.040   52.380952  29  29  30  29     C          29.25   \n",
      "\n",
      "        std        Sx true_mean+ true_mean-  \n",
      "0  1.000000  1.000000        NaN        NaN  \n",
      "1  0.000000  0.500000   -1.72622   -3.27378  \n",
      "2  0.957427  0.978714   -4.73538   -7.76462  \n",
      "3  1.732051  1.366025   -6.88599    -11.114  \n",
      "4  0.500000  0.750000   -8.58933   -10.9107  \n",
      "\n",
      "dat455\n",
      "\n",
      "   Sample  Thickness  %Reduction   1   2   3   4 scale  mean_hardness  \\\n",
      "0       1      0.080         NaN  32  32  33  31     C          32.00   \n",
      "1       2      0.072       34.00  32  32  33  34     C          32.75   \n",
      "2       3      0.065       18.75  35  34  35  35     C          34.75   \n",
      "3       4      0.057       28.75  32  33  33  32     C          32.50   \n",
      "4       5      0.043       46.25  32  33  34  32     C          32.75   \n",
      "\n",
      "        std        Sx true_mean+ true_mean-  \n",
      "0  0.816497  0.816497        NaN        NaN  \n",
      "1  0.957427  0.886962   0.622629   -2.12263  \n",
      "2  0.500000  0.658248   -1.73132   -3.76868  \n",
      "3  0.577350  0.696923   0.578533   -1.57853  \n",
      "4  0.957427  0.886962   0.622629   -2.12263  \n",
      "\n",
      "dat300\n",
      "\n",
      "   Sample  Thickness  %Reduction   1   2   3     4 scale  mean_hardness  \\\n",
      "0       1      0.091         NaN  30  30  30  30.0     C         30.000   \n",
      "1       2      0.080   12.087912  30  30  31  30.0     C         30.250   \n",
      "2       3      0.072   20.879121  30  29  30  31.0     C         30.000   \n",
      "3       4      0.053   41.758242  31  31  30  32.0     C         31.000   \n",
      "4       5      0.048   47.252747  34  33  34  35.5     C         34.125   \n",
      "\n",
      "        std        Sx true_mean+ true_mean-  \n",
      "0  0.000000  0.000000        NaN        NaN  \n",
      "1  0.500000  0.250000   0.136891  -0.636891  \n",
      "2  0.816497  0.408248    0.63179   -0.63179  \n",
      "3  0.816497  0.408248   -0.36821   -1.63179  \n",
      "4  1.030776  0.515388    -3.3274    -4.9226  \n"
     ]
    }
   ],
   "source": [
    "# This \n",
    "#dfs = [dat420,dat440,dat455,dat300]\n",
    "print trueMean(dfs,5.,5.)\n",
    "#print trueMean(dfs,5.,5.)\n",
    "print 'dat420\\n\\n',dfs['dat420']\n",
    "print '\\ndat440\\n\\n',dfs['dat440']\n",
    "print '\\ndat455\\n\\n',dfs['dat455']\n",
    "print '\\ndat300\\n\\n',dfs['dat300']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '~/Documents/ME365/Lab4/'\n",
    "files = ['Lab4_420G4_stat.xlsx','Lab4_440AG4_stat.xlsx','Lab4_Custom_455G4_stat.xlsx','Lab4_Nimark_300G4_stat.xlsx']\n",
    "for df,fileName in zip(dfs.keys(),files):\n",
    "    dfs[df].to_excel(path + fileName)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
